{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "#from PIL import Image\n",
    "import random\n",
    "#import tensorflow as tf\n",
    "#import re\n",
    "#import datetime\n",
    "#import io\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "#import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.metrics.distance import edit_distance\n",
    "#import string\n",
    "#from utils import generate_token_index\n",
    "#from utils import score_prediction, generate_token_index, y_labels, generate_dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxTextLen = 30\n",
    "\n",
    "dataset_orig = []\n",
    "\n",
    "f=open(data_folder + 'words.txt')\n",
    "chars = set()\n",
    "for line in f:\n",
    "    # ignore comment line\n",
    "    if not line or line[0]=='#':\n",
    "        continue\n",
    "\n",
    "    lineSplit = line.strip().split(' ')\n",
    "    assert len(lineSplit) >= 9\n",
    "\n",
    "    # filename: part1-part2-part3 --> part1/part1-part2/part1-part2-part3.png\n",
    "    fileNameSplit = lineSplit[0].split('-')\n",
    "    fileName = data_folder + 'words/' + fileNameSplit[0] + '/' + fileNameSplit[0] + '-' + fileNameSplit[1] + '/' + lineSplit[0] + '.png'\n",
    "\n",
    "    # GT text are columns starting at 9\n",
    "    gtText = ' '.join(lineSplit[8:])[:maxTextLen]\n",
    "    chars = chars.union(set(list(gtText)))\n",
    "\n",
    "    # put sample into list\n",
    "    dataset_orig.append((gtText, fileName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('A', '../data/words/a01/a01-000u/a01-000u-00-00.png')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select only a fraction\n",
    "fraction = 0.01\n",
    "max_len = int(len(dataset_orig) * fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.randint(0, len(dataset_orig), max_len)\n",
    "dataset = [dataset_orig[j] for j in indices]\n",
    "#len(dataset)\n",
    "#dataset = dataset_orig\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(',', '../data/words/l01/l01-133/l01-133-00-13.png')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 128\n",
    "\n",
    "y_size = dim\n",
    "x_size = dim * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_preprocessing(dataset, y_size, x_size):\n",
    "    imgs = []\n",
    "    words = []\n",
    "\n",
    "    for ind in range(len(dataset)):\n",
    "\n",
    "    #for ind in range(30):\n",
    "    #    print(ind)\n",
    "        fpath = dataset[ind][1]\n",
    "        #print(file)\n",
    "        img = cv2.imread(fpath, 0)\n",
    "        if img is not None:            \n",
    "            (wt, ht) = x_size, y_size\n",
    "            (h, w) = img.shape\n",
    "            fx = w / wt\n",
    "            fy = h / ht\n",
    "            f = max(fx, fy)\n",
    "            newSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1)) # scale according to f (result at least 1 and at most wt or ht)\n",
    "            img = cv2.resize(img, newSize)\n",
    "            target = np.ones([ht, wt]) * 255\n",
    "            target[0:newSize[1], 0:newSize[0]] = img\n",
    "\n",
    "            # transpose for TF\n",
    "            #img = cv2.transpose(target)\n",
    "\n",
    "            img = target\n",
    "            \n",
    "            # normalize\n",
    "            (m, s) = cv2.meanStdDev(img)\n",
    "            m = m[0][0]\n",
    "            s = s[0][0]\n",
    "            img = img - m\n",
    "            img = img / s if s>0 else img            \n",
    "            \n",
    "            imgs.append(img)\n",
    "            words.append(dataset[ind][0])\n",
    "\n",
    "    array_images = np.asarray(imgs)\n",
    "    \n",
    "    return array_images, words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_images, words = new_preprocessing(dataset, y_size, x_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 128, 384)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAADKCAYAAACYPCvsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARBEATZ+A9y12hW/NDN7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c79efd0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word =  met\n"
     ]
    }
   ],
   "source": [
    "index = random.randint(0, array_images.shape[0] - 1)\n",
    "plt.figure(figsize=(9, 9)) \n",
    "#plt.imshow(np.reshape(array_images[index, :, :], (y_size, x_size)), cmap=plt.get_cmap('gray'))\n",
    "plt.imshow(array_images[index, :, :], cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "print(\"word = \", words[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target_texts = []\n",
    "max_decoder_seq_length = 0.\n",
    "decoder_tokens = set()\n",
    "\n",
    "for word in words:\n",
    "#    word = '[' + word + ']'\n",
    "    decoder_tokens.add('[')\n",
    "    decoder_tokens.add(']')\n",
    "\n",
    "    if len(word) > max_decoder_seq_length:\n",
    "        max_decoder_seq_length = len(word)\n",
    "    for letter in word:\n",
    "        decoder_tokens.add(letter)\n",
    "    #    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    \n",
    "#    input_texts.append(input_text)\n",
    "#    target_texts.append(word\n",
    "\n",
    "max_decoder_seq_length += 2    \n",
    "decoder_tokens  = list(decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_token_index(decoder_tokens):\n",
    "    #decoder_tokens += ':[]'\n",
    "    num_decoder_tokens = len(decoder_tokens)\n",
    "    \n",
    "    return dict((k, v) for v, k in enumerate(decoder_tokens)), num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_token_index, num_decoder_tokens = generate_token_index(decoder_tokens)\n",
    "#max_decoder_seq_length = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tran test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#array_images = np.reshape(array_images, (-1, y_size, x_size, 1))\n",
    "array_images = np.reshape(array_images, (-1, y_size, x_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 46\n",
    "test_size=0.1\n",
    "val_size = 0.1\n",
    "array_images_train_val, array_images_test, words_train_val, words_test = train_test_split(array_images, words, test_size=test_size, random_state=random_state)  \n",
    "array_images_train, array_images_val, words_train, words_val = train_test_split(array_images_train_val, words_train_val, test_size=val_size, random_state=random_state)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 128, 384, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def y_labels(ys, max_decoder_seq_length, num_decoder_tokens, target_token_index):\n",
    "\n",
    "    decoder_input_data = np.zeros( (len(ys),  max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "    decoder_target_data = np.zeros( (len(ys), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(ys):\n",
    "        target_text = '[' + target_text + ']'\n",
    "        \n",
    "        for t, char in enumerate(target_text):\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create one-hot labelling for target sequence\n",
    "decoder_input_data_train, decoder_target_data_train = y_labels(words_train, max_decoder_seq_length, num_decoder_tokens, target_token_index)\n",
    "decoder_input_data_val, decoder_target_data_val = y_labels(words_val, max_decoder_seq_length, num_decoder_tokens, target_token_index)\n",
    "decoder_input_data_test, decoder_target_data_test = y_labels(words_test, max_decoder_seq_length, num_decoder_tokens, target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 19, 71)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "# define data preparation\n",
    "#train_datagen = ImageDataGenerator(\n",
    "#                             #featurewise_center=True, featurewise_std_normalization=True, \n",
    "#                             #samplewise_center=True, samplewise_std_normalization=True,\n",
    "##                             rescale=1./255,\n",
    "#                             #rotation_range=5, width_shift_range=0.05, height_shift_range=0.1, \n",
    "#                             #shear_range = 3, zoom_range = [0.9, 1.1], \n",
    "#                             rotation_range=5, width_shift_range=0.1, height_shift_range=0.2, \n",
    "#                             shear_range = 5, zoom_range = [0.8, 1.2], \n",
    "#                             horizontal_flip=False, data_format='channels_last')\n",
    "\n",
    "#val_datagen = ImageDataGenerator(\n",
    "#                                 #rescale=1./255, \n",
    "#                                 #samplewise_center=True, samplewise_std_normalization=True,\n",
    "#                                 data_format='channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, Conv2D, MaxPooling2D, Reshape, Dropout, BatchNormalization, Activation, Bidirectional, concatenate, add, Lambda, Permute\n",
    "from keras.callbacks import EarlyStopping\n",
    "#import keras.backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 512  # Latent dimensionality of the encoding space.\n",
    "#optimizer\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_encoder (InputLayer)      (None, 128, 384, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 128, 384, 16) 784         input_encoder[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_1 (BatchNormalizatio (None, 128, 384, 16) 64          conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 384, 16) 0           batch_norm_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_1 (MaxPooling2D)        (None, 64, 192, 16)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 64, 192, 32)  12800       maxpool_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_2 (BatchNormalizatio (None, 64, 192, 32)  128         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 192, 32)  0           batch_norm_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_2 (MaxPooling2D)        (None, 32, 96, 32)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 32, 96, 64)   51200       maxpool_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_3 (BatchNormalizatio (None, 32, 96, 64)   256         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 96, 64)   0           batch_norm_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_3 (MaxPooling2D)        (None, 16, 48, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 16, 48, 128)  73728       maxpool_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_4 (BatchNormalizatio (None, 16, 48, 128)  512         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 48, 128)  0           batch_norm_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_4 (MaxPooling2D)        (None, 8, 24, 128)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 8, 24, 256)   294912      maxpool_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_5 (BatchNormalizatio (None, 8, 24, 256)   1024        conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 24, 256)   0           batch_norm_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_5 (MaxPooling2D)        (None, 4, 12, 256)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 4, 12, 512)   1179648     maxpool_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm_6 (BatchNormalizatio (None, 4, 12, 512)   2048        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4, 12, 512)   0           batch_norm_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "maxpool_6 (MaxPooling2D)        (None, 2, 6, 512)    0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 12, 512)      0           maxpool_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_decoder_teacher_forcing ( (None, 19, 71)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_encoder (LSTM)             [(None, 512), (None, 2099200     reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_decoder (LSTM)             [(None, 19, 512), (N 1196032     input_decoder_teacher_forcing[0][\n",
      "                                                                 lstm_encoder[0][1]               \n",
      "                                                                 lstm_encoder[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_dense (TimeDis (None, 19, 71)       36423       lstm_decoder[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,948,759\n",
      "Trainable params: 4,946,743\n",
      "Non-trainable params: 2,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(y_size, x_size, 1), name='input_encoder')\n",
    "\n",
    "#encoder_inputs = Input(shape=(92, 248, 1), name='input_encoder')\n",
    "\n",
    "#(7,7)\n",
    "encoder_layer = Conv2D(16, (7, 7), padding='same', use_bias=False, name='conv_1')(encoder_inputs)\n",
    "encoder_layer = BatchNormalization(name='batch_norm_1')(encoder_layer)\n",
    "encoder_layer = Activation('relu', name='activation_1')(encoder_layer)\n",
    "encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_1')(encoder_layer)\n",
    "\n",
    "#(7,7)\n",
    "encoder_layer = Conv2D(32, (5, 5), padding='same', use_bias=False, name='conv_2')(encoder_layer)\n",
    "encoder_layer = BatchNormalization(name='batch_norm_2')(encoder_layer)\n",
    "encoder_layer = Activation('relu', name='activation_2')(encoder_layer)\n",
    "encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_2')(encoder_layer)\n",
    "\n",
    "#(5,5)\n",
    "encoder_layer = Conv2D(64, (5, 5), padding='same', use_bias=False, name='conv_3')(encoder_layer)\n",
    "encoder_layer = BatchNormalization(name='batch_norm_3')(encoder_layer)\n",
    "encoder_layer = Activation('relu', name='activation_3')(encoder_layer)\n",
    "encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_3')(encoder_layer)\n",
    "\n",
    "#(5,5)\n",
    "encoder_layer = Conv2D(128, (3, 3), padding='same', use_bias=False, name='conv_4')(encoder_layer)\n",
    "encoder_layer = BatchNormalization(name='batch_norm_4')(encoder_layer)\n",
    "encoder_layer = Activation('relu', name='activation_4')(encoder_layer)\n",
    "encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_4')(encoder_layer)\n",
    "\n",
    "#(3,3)\n",
    "encoder_layer = Conv2D(256, (3, 3), padding='same', use_bias=False, name='conv_5')(encoder_layer)\n",
    "encoder_layer = BatchNormalization(name='batch_norm_5')(encoder_layer)\n",
    "encoder_layer = Activation('relu', name='activation_5')(encoder_layer)\n",
    "encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_5')(encoder_layer)\n",
    "\n",
    "#(3,3)\n",
    "encoder_layer = Conv2D(512, (3, 3), padding='same', use_bias=False, name='conv_6')(encoder_layer)\n",
    "encoder_layer = BatchNormalization(name='batch_norm_6')(encoder_layer)\n",
    "encoder_layer = Activation('relu', name='activation_6')(encoder_layer)\n",
    "encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_6')(encoder_layer)\n",
    "\n",
    "\n",
    "#(2,2)\n",
    "#encoder_layer = Conv2D(512, (3, 3), padding='same', use_bias=False, name='conv_6')(encoder_layer)\n",
    "#encoder_layer = BatchNormalization(name='batch_norm_6')(encoder_layer)\n",
    "#encoder_layer = Activation('relu', name='activation_6')(encoder_layer)\n",
    "#encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_6')(encoder_layer)\n",
    "\n",
    "\n",
    "#(3,3)\n",
    "#encoder_layer = Conv2D(512, (3, 3), padding='same', use_bias=False, name='conv_6')(encoder_layer)\n",
    "#encoder_layer = BatchNormalization(name='batch_norm_6')(encoder_layer)\n",
    "#encoder_layer = Activation('relu', name='activation_6')(encoder_layer)\n",
    "#encoder_layer = MaxPooling2D(pool_size=(2, 2), padding='valid', name='maxpool_6')(encoder_layer)\n",
    "\n",
    "conv_shapes = encoder_layer.shape[1:]\n",
    "timesteps = int(conv_shapes[0]*conv_shapes[1])\n",
    "num_features = int(conv_shapes[2])\n",
    "\n",
    "encoder_layer = Reshape((-1, num_features), name='reshape')(encoder_layer)\n",
    "\n",
    "#encoder\n",
    "encoder = LSTM(latent_dim, return_state=True, name='lstm_encoder')\n",
    "_, state_h, state_c = encoder(encoder_layer)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#decoder\n",
    "decoder_inputs = Input(shape=(max_decoder_seq_length, num_decoder_tokens), name='input_decoder_teacher_forcing')\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='lstm_decoder')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense_time_dist = TimeDistributed(Dense(num_decoder_tokens, activation='softmax'), name='time_distributed_dense')\n",
    "decoder_outputs = decoder_dense_time_dist(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = False\n",
    "\n",
    "batch_size = 128  # Batch size for training.\n",
    "epochs = 50 # Number of epochs to train for.\n",
    "\n",
    "n_times_aug = 1\n",
    "\n",
    "# Early stopping  \n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "if train == True:    \n",
    "    # Run training\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "\n",
    "    model.fit([array_images_train, decoder_input_data_train], decoder_target_data_train, batch_size=batch_size,\n",
    "              epochs=epochs, validation_data = ([array_images_val, decoder_input_data_val], decoder_target_data_val),\n",
    "              verbose=1, callbacks=[])\n",
    "    \n",
    "#    model.fit_generator(train_datagen.flow([array_images_train, decoder_input_data_train], decoder_target_data_train, batch_size=batch_size),\n",
    "#                        steps_per_epoch = n_times_aug * len(array_images_train) / batch_size, epochs=epochs, \n",
    "#                        validation_data = val_datagen.flow([array_images_val, decoder_input_data_val], decoder_target_data_val, batch_size=batch_size),\n",
    "#                        validation_steps =  1, verbose=1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giovanni/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_decoder was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_encoder_1/while/Exit_3:0' shape=(?, 512) dtype=float32>, <tf.Tensor 'lstm_encoder_1/while/Exit_4:0' shape=(?, 512) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"../snapshots/graph.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../snapshots/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if train == False:\n",
    "#model.save('../snapshots/model_IAM.h5')\n",
    "#model.save_weights(\"../snapshots/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train == False:\n",
    "    from keras.models import load_model, model_from_json\n",
    "    json_file = open('../snapshots/graph.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"../snapshots/weights.h5\")    \n",
    "#    model = load_model('../snapshots/model_IAM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights(\"../snapshots/weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 71 and 81 for 'lstm_decoder_6/MatMul' (op: 'MatMul') with input shapes: [?,71], [81,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 71 and 81 for 'lstm_decoder_6/MatMul' (op: 'MatMul') with input shapes: [?,71], [81,512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0ff40580fde1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdecoder_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lstm_decoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_inputs_inference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_states_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdecoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0moriginal_input_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_input_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   2192\u001b[0m                                       \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2193\u001b[0m                                       \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2194\u001b[0;31m                                       initial_state=initial_state)\n\u001b[0m\u001b[1;32m   2195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    647\u001b[0m                                              \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m                                              input_length=timesteps)\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2921\u001b[0m         \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2922\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2923\u001b[0m         output_ta = tensor_array_ops.TensorArray(\n\u001b[1;32m   2924\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         last_output, outputs, states = K.rnn(step,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m   1950\u001b[0m                 \u001b[0minputs_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m                 \u001b[0minputs_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m             \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m             \u001b[0mx_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m             \u001b[0mx_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2055\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2057\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4558\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4559\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4560\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4561\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4562\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 71 and 81 for 'lstm_decoder_6/MatMul' (op: 'MatMul') with input shapes: [?,71], [81,512]."
     ]
    }
   ],
   "source": [
    "# Define inference models \n",
    "#encoder\n",
    "#encoder_inputs_inference = Input(shape=(x_size, y_size, 1), name='input_encoder_inference')\n",
    "encoder_inference = Model(model.get_input_at(0)[0], model.get_layer(\"lstm_encoder\").output[1:])\n",
    "\n",
    "#decoder\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_inputs_inference = Input(shape=(1, num_decoder_tokens), name='input_decoder_inference')\n",
    "\n",
    "decoder_lstm = model.get_layer(\"lstm_decoder\")\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_inference, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "#dense layer\n",
    "decoder_dense = model.get_layer('time_distributed_dense').layer\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#inference\n",
    "decoder_inference = Model([decoder_inputs_inference] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq, max_decoder_seq_length=5):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_inference.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['[']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_inference.predict( [target_seq] + states_value )\n",
    "           \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == ']'): \n",
    "            #or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_train = []\n",
    "\n",
    "for ind in range(len(words_train)):    \n",
    "    #row_pred = []\n",
    "\n",
    "    input_seq = np.reshape( array_images_train[ind,:,:], (-1, y_size,  x_size, 1) )\n",
    "    \n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    decoded_sentence = decoded_sentence.replace(\"]\", \"\")\n",
    "    \n",
    "    #row_pred.append(words_train[ind])\n",
    "    #row_pred.append(decoded_sentence)\n",
    "    \n",
    "    pred_train.append(decoded_sentence)\n",
    "    \n",
    "    #print('Data', words_test[ind], '-', ind, 'out of', len(words_test))\n",
    "    print('True sequence:', words_train[ind])\n",
    "    print('Decoded sequence:', decoded_sentence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_test = []\n",
    "\n",
    "for ind in range(len(words_test)):    \n",
    "    #row_pred = []\n",
    "\n",
    "    input_seq = np.reshape( array_images_test[ind,:,:], (-1, y_size,  x_size, 1) )\n",
    "    \n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    decoded_sentence = decoded_sentence.replace(\"]\", \"\")\n",
    "    \n",
    "    #row_pred.append(words_test[ind])\n",
    "    #row_pred.append(decoded_sentence)\n",
    "    \n",
    "    pred_test.append(decoded_sentence)\n",
    "    \n",
    "    #print('Data', words_test[ind], '-', ind, 'out of', len(words_test))\n",
    "    print('True sentence:', words_test[ind])\n",
    "    print('Decoded sentence:', decoded_sentence, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_prediction(y_true, y_pred):\n",
    "    words_identified = 0\n",
    "    characters_identified = 0\n",
    "    char_tot = 0\n",
    "#    CER = 0\n",
    "\n",
    "#    list_accuracy_characters = []\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        #pred_row = [y_true[i], y_pred[i]] \n",
    "        \n",
    "        #check if date are the same\n",
    "        #if pred_row[0] == pred_row[1]:\n",
    "        if y_true[i] == y_pred[i]:\n",
    "\n",
    "            words_identified += 1\n",
    "            \n",
    "#        if len(pred_row[1]) < len(pred_row[0]):\n",
    "#            pred_row[1] += '-' * (len(pred_row[0]) - len(pred_row[1]))    \n",
    "#        elif len(pred_row[1]) > len(pred_row[1]):\n",
    "\n",
    "#            pred_row[1] = pred_row[1][0:len(pred_row[0])]\n",
    "\n",
    "        #check the number of characters that are the same\n",
    " #       print(y_true[i])\n",
    " #       print(y_pred[i])\n",
    "        \n",
    "        levenshtein_distance = edit_distance(y_true[i], y_pred[i])\n",
    "        n_char = np.maximum(len(y_true[i]), len(y_pred[i]))\n",
    "        \n",
    "        normalized_distance = levenshtein_distance/n_char\n",
    "\n",
    "        characters_identified += normalized_distance\n",
    "#        char_tot += n_char\n",
    "        \n",
    "#        CER += normalized_distance\n",
    "        \n",
    "#        print(len(y_true[i]))\n",
    "#        for k in range(len(y_true[i])):\n",
    "#            print()\n",
    "#            if y_true[i][k] == y_pred[1][k]:\n",
    "#        characters_identified += 1\n",
    "#        char_tot += 1\n",
    "\n",
    "    # array_accuracy_characters = np.asarray(list_accuracy_characters)\n",
    "    CER = float((characters_identified) / len(y_true))\n",
    "    WER = (len(y_pred) - words_identified)/len(y_pred) \n",
    "        \n",
    "    return CER, WER\n",
    "#    return WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CER_test, WER_test = score_prediction(words_test, pred_test)\n",
    "#WER_test = score_prediction(words_test, pred_test)\n",
    "print('CER: ', round(CER_test * 100, 3), '%')\n",
    "print('WER: ', round(WER_test * 100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CER_train, WER_train = score_prediction(words_train, pred_train)\n",
    "#print('CER: ', round(CER_train * 100, 3), '%')\n",
    "print('CER: ', round(CER_train * 100, 3), '%')\n",
    "print('WER: ', round(WER_train * 100, 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
